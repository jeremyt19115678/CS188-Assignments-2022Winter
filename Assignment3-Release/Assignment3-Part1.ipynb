{"cells":[{"cell_type":"markdown","metadata":{"id":"nfmYpd7cEAA4"},"source":["# Assignment 3 - Part1\n","In this assignment we will use pretrained ResNet to do classification on the Stanford Actions dataset, which has 40 action categories."]},{"cell_type":"markdown","metadata":{"id":"DZyWdzaaWILA"},"source":["# Setup Code"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YjzsBhslWJFZ"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"twuuuKg3Yc0P"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hLir_mUQYi6d"},"outputs":[],"source":["import os\n","\n","# TODO: Fill in the Google Drive path where you uploaded the assignment\n","# Example: If you create a 188 folder and put all the files under Assignment1 folder, then '188/Assignment1'\n","# GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = '188/Assignment1'\n","GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = '188/Assignment3'\n","GOOGLE_DRIVE_PATH = os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n","print(os.listdir(GOOGLE_DRIVE_PATH))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RIzoPO3zY1Mf"},"outputs":[],"source":["import sys\n","sys.path.append(GOOGLE_DRIVE_PATH)"]},{"cell_type":"markdown","metadata":{"id":"tkOmNbPdSqLm"},"source":["Now we are going to untar the actions folder. Don't worry! This time the file is much smaller."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D9svhBylSd28"},"outputs":[],"source":["!tar -xvf \"/content/drive/My Drive/188/Assignment3/actions.tar.xz\" -C \"/content/drive/My Drive/188/Assignment3/\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"7eEC_SaAEAA9"},"outputs":[],"source":["import torch\n","import torchvision.models as models\n","from torch import nn\n","from tqdm import tqdm\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"908TXapaEAA-"},"source":["## Compare different features\n","Recall that in Assignment1, we used color histogram features for KNN classification.\n","In this assignment, we will use features from ResNet18 and compare the results.\n","\n","#### Color Features\n","We will first used the color features as in Assignment1. You do not need to implement anything here. Copy your implementation of KNN in model.py, then run the codes below."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r0Q42WMPEAA_"},"outputs":[],"source":["import dataset\n","\n","training_data = dataset.Actions(\n","    split = 'train',\n","    root_dir = GOOGLE_DRIVE_PATH,\n","    color_feature = True\n",")\n","print (len(training_data))\n","\n","test_data = dataset.Actions(\n","    split='test',\n","    root_dir = GOOGLE_DRIVE_PATH,\n","    color_feature = True\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fiXGooWPEABA"},"outputs":[],"source":["import torch\n","from tqdm import tqdm\n","import cv2\n","\n","sub_sample = list(range(0, len(training_data), 25))\n","training_data1 = torch.utils.data.Subset(training_data, sub_sample)\n","training_loader1 = torch.utils.data.DataLoader(training_data1, batch_size=64, shuffle=False, num_workers=2)\n","\n","all_features = []\n","all_labels = []\n","\n","for i, data in enumerate(tqdm((training_loader1))):\n","    inputs, label = data\n","\n","    all_features.append(inputs)\n","    all_labels.append(label)\n","\n","all_features = torch.cat(all_features, dim=0)\n","all_labels = torch.cat(all_labels, dim=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MhQM4J1zEABA"},"outputs":[],"source":["import model\n","from model import *\n","\n","test_loader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=False, num_workers=2)\n","\n","total_acc = 0\n","\n","knn = KnnClassifier(all_features, all_labels)\n","for i, data in enumerate(tqdm((test_loader))):\n","    inputs, label = data\n","    acc = knn.check_accuracy(inputs, label, k=1, quiet=False)\n","    total_acc += acc\n","    \n","total_acc /= i\n","print (\"total accuracy is %.2f\"%(total_acc/100))"]},{"cell_type":"markdown","metadata":{"id":"x1jC5M_TEABB"},"source":["The total accuracy is about 4%\n","\n","### ResNet Features\n","We then use features extracted from ResNet18."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"dYqvRxPwEABC"},"outputs":[],"source":["import dataset\n","\n","training_data = dataset.Actions(\n","    split = 'train',\n","    root_dir = GOOGLE_DRIVE_PATH\n",")\n","print (len(training_data))\n","\n","test_data = dataset.Actions(\n","    split='test',\n","    root_dir = GOOGLE_DRIVE_PATH\n",")"]},{"cell_type":"markdown","metadata":{"id":"XjliE15VEABD"},"source":["Implement the Resnet class in model.py. First write the case where \"mode=feature\". This means that we want to discard the final FC layer of ResNet18."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XgwjEXXeEABD"},"outputs":[],"source":["from model import *\n","resnet18 = Resnet(mode='feature')\n","\n","sub_sample = list(range(0, len(training_data), 25))\n","training_data1 = torch.utils.data.Subset(training_data, sub_sample)\n","training_loader1 = torch.utils.data.DataLoader(training_data1, batch_size=64, shuffle=False, num_workers=2)\n","\n","all_features = []\n","all_labels = []\n","\n","for i, data in enumerate(tqdm((training_loader1))):\n","    inputs, label = data\n","    cnn_features = resnet18(inputs)\n","\n","    all_features.append(cnn_features)\n","    all_labels.append(label)\n","\n","all_features = torch.cat(all_features, dim=0)\n","all_labels = torch.cat(all_labels, dim=0)"]},{"cell_type":"markdown","metadata":{"id":"wy7LmssbEABE"},"source":["And then we will use pretrained resnet features to do KNN classification."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gYOgYklNEABE"},"outputs":[],"source":["test_loader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=False, num_workers=2)\n","\n","total_acc = 0\n","\n","knn = KnnClassifier(all_features, all_labels)\n","for i, data in enumerate(tqdm((test_loader))):\n","    inputs, label = data\n","    features = resnet18(inputs)\n","    acc = knn.check_accuracy(features, label, k=1, quiet=False)\n","    total_acc += acc\n","    \n","total_acc /= i\n","print (\"total accuracy is %.2f\"%(total_acc/100))"]},{"cell_type":"markdown","metadata":{"id":"FxgEn93iEABF"},"source":["I can get 30% accuracy. What about you?"]},{"cell_type":"markdown","metadata":{"id":"gq_tEmKNEABF"},"source":["## What's your opinion on using different features? Pros & Cons?\n","\n","[Your answer]"]},{"cell_type":"markdown","source":["### Retrieve the most relevant images\n","\n","We put two images: image1.jpg and image2.jpg in the folder. Please write your code, use pretrained resnet features to output **5 top relevant images** to each image."],"metadata":{"id":"G9BwqxFCpgbH"}},{"cell_type":"code","source":["# Your Code here"],"metadata":{"id":"Q8ww_U2WpxW0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ttauhWfzEABF"},"source":["### Pretrained ResNet features + Linear Classifier\n","Then we implement the \"linear\" mode in Resnet class in model.py. Remember to freeze the features of ResNet.\n","In this implementation we use linear classifier to do classification on the dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BY2nTJ6xEABG"},"outputs":[],"source":["from model import *\n","\n","torch.manual_seed(0)\n","resnet18 = Resnet(mode='linear').cuda()\n","\n","# Your Code: training loader / test loader with batch size 64\n"," \n","# Your code: SGD optimizer with lr 0.01 and momentum 0.9\n","\n","# Your code: define loss as cross entropy loss\n","\n","for epoch in range(5):#If you run out of GPU, just run 1 epoch\n","    for i, data in enumerate(tqdm((training_loader))):\n","        # Every data instance is an input + label pair\n","        inputs, labels = data\n","        inputs = inputs.cuda()\n","        labels = labels.cuda()\n","\n","        optimizer.zero_grad()\n","\n","        # Your Code: Make predictions for this batch\n","\n","        # Your Code: Compute the loss and its gradients\n","\n","        # Your Code: Optimizer Adjust learning weights\n","    \n","    total_acc = .0\n","    len_samples = 0\n","    \n","    for i, data in enumerate(tqdm((test_loader))):\n","        inputs, labels = data\n","        len_samples += inputs.shape[0]\n","        inputs = inputs.cuda()\n","        labels = labels.cuda()\n","        \n","        # Your Code: Make predictions for this batch\n","\n","        # Your Code: Use argmax to extract predicted labels\n","        \n","        acc = torch.sum(torch.eq(outputs, labels))\n","        total_acc += acc.item()\n","    total_acc /= len_samples\n","        \n","    print (total_acc)\n","    "]},{"cell_type":"markdown","metadata":{"id":"B7_wHfEQEABG"},"source":["I can get 65% accuracy! What about you?\n","\n","### End-to-end finetune resnet\n","In this implementation, instead of freezing resnet features, we want to finetune it. Implement the \"finetune\" mode in Resnet class in model.py. The implementation is the same as the \"linear\" mode, except that we do not need to set requires_grad to False to freeze the features. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0fCZZ9erEABG"},"outputs":[],"source":["from model import *\n","\n","torch.manual_seed(0)\n","resnet18 = Resnet(mode='finetune').cuda()\n","    \n","# Your Code: training loader / test loader with batch size 64\n"," \n","# Your code: SGD optimizer with lr 0.01 and momentum 0.9\n","\n","# Your code: define loss as cross entropy loss\n","\n","for epoch in range(5):#If you run out of GPU, just run 1 epoch\n","    for i, data in enumerate(tqdm((training_loader))):\n","        # Every data instance is an input + label pair\n","\n","for epoch in range(5):\n","    for i, data in enumerate(tqdm((training_loader))):\n","        # Every data instance is an input + label pair\n","        inputs, labels = data\n","        inputs = inputs.cuda()\n","        labels = labels.cuda()\n","\n","        optimizer.zero_grad()\n","\n","        # Your Code: Make predictions for this batch\n","\n","        # Your Code: Compute the loss and its gradients\n","\n","        # Your Code: Optimizer Adjust learning weights\n","    \n","    total_acc = .0\n","    len_samples = 0\n","    \n","    for i, data in enumerate(tqdm((test_loader))):\n","        inputs, labels = data\n","        len_samples += inputs.shape[0]\n","        inputs = inputs.cuda()\n","        labels = labels.cuda()\n","        # Your Code: Make predictions for this batch\n","\n","        # Your Code: Use argmax to extract predicted labels\n","        \n","        acc = torch.sum(torch.eq(outputs, labels))\n","        total_acc += acc.item()\n","    total_acc /= len_samples\n","        \n","    print (total_acc)\n","    "]},{"cell_type":"markdown","metadata":{"id":"npulIc0FEABH"},"source":["I can get 75% accuracy. What about you?"]},{"cell_type":"markdown","metadata":{"id":"xJYnnk1xEABH"},"source":["### Compare using pretrained resnet features for classification / end-to-end finetuning\n","\n","[Your answer]"]},{"cell_type":"markdown","metadata":{"id":"HKPf9m14EABH"},"source":["## CAM\n","\n","Now we will implement Prof. Zhou's famous paper: \"Learning Deep Features for Discriminative Localization\", in which he proposed class activation mapping (CAM). The main equation is:\n","$$S_{c}=\\sum_{k} w_{k}^{c} \\sum_{x, y} f_{k}(x, y)=\\sum_{x, y} \\sum_{k} w_{k}^{c} f_{k}(x, y)$$\n","where $f_{k}(x, y)$ represents the activation of unit k in the last convolutional layer, which is layer4 in resnet18.\n","\n","For more detailed implementation, please refer to the github repo: https://github.com/zhoubolei/CAM\n","\n","Please implement the CAM function in model.py. Specifically, given convolutional features, weights and a class index, CAM will output the reasons for classifying the image to the class, thus making CNN interpretable."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yNrYHWoUEABI","scrolled":true},"outputs":[],"source":["from model import *\n","\n","resnet18.eval()\n","\n","finalconv_name = 'layer4'\n","# hook the feature extractor\n","features_blobs = []\n","\n","def hook_feature(module, input, output):\n","    features_blobs.append(output.data.cpu().numpy())\n","\n","resnet18.resnet._modules.get(finalconv_name).register_forward_hook(hook_feature)\n","\n","params = list(resnet18.parameters())\n","weight_softmax = np.squeeze(params[-2].data.cpu().numpy())\n","\n","classes = ['applauding', 'blowing_bubbles', 'brushing_teeth', 'cleaning_the_floor', 'climbing', 'cooking', 'cutting_trees', 'cutting_vegetables', 'drinking', 'feeding_a_horse', 'fishing', 'fixing_a_bike', 'fixing_a_car', 'gardening', 'holding_an_umbrella', 'jumping', 'looking_through_a_microscope', 'looking_through_a_telescope', 'playing_guitar', 'playing_violin', 'pouring_liquid', 'pushing_a_cart', 'reading', 'phoning', 'riding_a_bike', 'riding_a_horse', 'rowing_a_boat', 'running', 'shooting_an_arrow', 'smoking', 'taking_photos', 'texting_message', 'throwing_frisby', 'using_a_computer', 'walking_the_dog', 'washing_dishes', 'watching_TV', 'waving_hands', 'writing_on_a_board', 'writing_on_a_book']\n","\n","test_data1 = torch.utils.data.Subset(test_data, list(range(0,1000,100)))\n","test_loader1 = torch.utils.data.DataLoader(test_data1, batch_size=1, shuffle=True, num_workers=2)\n","\n","figure = plt.figure(figsize=(24, 6))\n","cols, rows = 10, 2\n","\n","for i, data in enumerate(tqdm((test_loader1))):\n","    features_blobs = []\n","    img, label = data\n","    img = img.cuda()\n","    \n","    logit = resnet18(img)\n","    \n","    h_x = F.softmax(logit, dim=1).data.squeeze()\n","    probs, idx = h_x.sort(0, True)\n","    probs = probs.cpu().numpy()\n","    idx = idx.cpu().numpy()\n","\n","    # generate class activation mapping for the top1 prediction\n","    CAMs = CAM(features_blobs[0], weight_softmax, [idx[0]])\n","\n","    img = img.squeeze().permute(1,2,0)\n","    height, width, _ = img.shape\n","    img = img.cpu().numpy()\n","    heatmap = cv2.applyColorMap(cv2.resize(CAMs[0],(width, height)), cv2.COLORMAP_JET)\n","\n","    result = heatmap * 0.3 + img * 0.5\n","    \n","    figure.add_subplot(rows, cols, i+1)\n","    plt.axis(\"off\")\n","    plt.title(classes[label])\n","    plt.imshow(img, cmap=\"gray\")\n","    \n","    figure.add_subplot(rows, cols, i+11)\n","    plt.axis(\"off\")\n","    plt.title(classes[idx[0]])\n","    plt.imshow(result, cmap=\"gray\")\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"jf_oma00EABI"},"source":["### What does your heatmap look like? How do they explain/affect the classification prediction?\n","\n","[Your Answer]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J3FJ7kpdEABI"},"outputs":[],"source":[""]}],"metadata":{"colab":{"name":"Assignment3-Part1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":0}
